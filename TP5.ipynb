{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration de Cuda dans Google Colab"
      ],
      "metadata": {
        "id": "qE-HbkLWqjJK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJjU5zI_-tjl"
      },
      "outputs": [],
      "source": [
        "!nvcc -V  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "HBZjh4P4-1HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On vérifie que l'on est bien connecté au GPU"
      ],
      "metadata": {
        "id": "YJw3IWdqtpfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "9gl_4Pn7_JR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chargement du plugin nvcc permettant de compiler/executer les programmes Cuda"
      ],
      "metadata": {
        "id": "NlBBvVVOt4Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "6YGSePh_Q_DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Un makefile est déjà à votre disposition pour compiler les programme du TP\n"
      ],
      "metadata": {
        "id": "0zrHyBuVuQpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Executez la cellule du Makefile\n",
        "\n",
        "Le makefile a été modifié pour les programmes puisse s'exécuter avec la GPU premium.\n",
        "\n"
      ],
      "metadata": {
        "id": "AWS3uSGwu2o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Makefile\n",
        "# Change the example variable to build a different source module (e.g. EXAMPLE=exercice01)\n",
        "EXAMPLE=program\n",
        "\n",
        "# Makefile variables \n",
        "# Add extra targets to OBJ with space separator e.g. If there is as source file random.c then add random.o to OBJ)\n",
        "# Add any additional dependancies (header files) to DEPS. e.g. if there is aheader file random.h required by your source modules then add this to DEPS.\n",
        "CC=gcc\n",
        "CFLAGS= -O3 -Wextra -fopenmp\n",
        "NVCC=nvcc\n",
        "NVCC_FLAGS= -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87\n",
        "OBJ=$(EXAMPLE).o\n",
        "DEPS=\n",
        "\n",
        "# Build rule for object files ($@ is left hand side of rule, $< is first item from the right hand side of rule)\n",
        "%.o : %.cu $(DEPS)\n",
        "\t$(NVCC) -c -o $@ $< $(NVCC_FLAGS) $(addprefix -Xcompiler ,$(CCFLAGS))\n",
        "\n",
        "# Make example ($^ is all items from right hand side of the rule)\n",
        "$(EXAMPLE) : $(OBJ)\n",
        "\t$(NVCC) -o $@ $^ $(NVCC_FLAGS) $(addprefix -Xcompiler ,$(CCFLAGS))\n",
        "\n",
        "# PHONY prevents make from doing something with a filename called clean\n",
        ".PHONY : clean\n",
        "clean:\n",
        "\trm -rf $(EXAMPLE) $(OBJ)"
      ],
      "metadata": {
        "id": "2VMs5wjdRU0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP5\n",
        "\n"
      ],
      "metadata": {
        "id": "ri3OU-i0vt2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.h\n",
        "#ifndef __UTILS_H__\n",
        "#define __UTILS_H__\n",
        "#include <stdio.h>\n",
        "\n",
        "static void HandleError( cudaError_t err,\n",
        "                         const char *file,\n",
        "                         int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))\n",
        "\n",
        "\n",
        "#define HANDLE_NULL( a ) {if (a == NULL) { \\\n",
        "                            printf( \"Host memory failed in %s at line %d\\n\", \\\n",
        "                                    __FILE__, __LINE__ ); \\\n",
        "                            exit( EXIT_FAILURE );}}\n",
        "\n",
        "template< typename T >\n",
        "void swap( T& a, T& b ) {\n",
        "    T t = a;\n",
        "    a = b;\n",
        "    b = t;\n",
        "}\n",
        "\n",
        "\n",
        "void* big_random_block( int size ) {\n",
        "    unsigned char *data = (unsigned char*)malloc( size );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "int* big_random_block_int( int size ) {\n",
        "    int *data = (int*)malloc( size * sizeof(int) );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "\n",
        "// a place for common kernels - starts here\n",
        "\n",
        "__device__ unsigned char value( float n1, float n2, int hue ) {\n",
        "    if (hue > 360)      hue -= 360;\n",
        "    else if (hue < 0)   hue += 360;\n",
        "\n",
        "    if (hue < 60)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*hue/60));\n",
        "    if (hue < 180)\n",
        "        return (unsigned char)(255 * n2);\n",
        "    if (hue < 240)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*(240-hue)/60));\n",
        "    return (unsigned char)(255 * n1);\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( unsigned char *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset*4 + 0] = value( m1, m2, h+120 );\n",
        "    optr[offset*4 + 1] = value( m1, m2, h );\n",
        "    optr[offset*4 + 2] = value( m1, m2, h -120 );\n",
        "    optr[offset*4 + 3] = 255;\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( uchar4 *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset].x = value( m1, m2, h+120 );\n",
        "    optr[offset].y = value( m1, m2, h );\n",
        "    optr[offset].z = value( m1, m2, h -120 );\n",
        "    optr[offset].w = 255;\n",
        "}\n",
        "\n",
        "\n",
        "#if _WIN32\n",
        "    //Windows threads.\n",
        "    #include <windows.h>\n",
        "\n",
        "    typedef HANDLE CUTThread;\n",
        "    typedef unsigned (WINAPI *CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC unsigned WINAPI\n",
        "    #define  CUT_THREADEND return 0\n",
        "\n",
        "#else\n",
        "    //POSIX threads.\n",
        "    #include <pthread.h>\n",
        "\n",
        "    typedef pthread_t CUTThread;\n",
        "    typedef void *(*CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC void\n",
        "    #define  CUT_THREADEND\n",
        "#endif\n",
        "\n",
        "//Create thread.\n",
        "CUTThread start_thread( CUT_THREADROUTINE, void *data );\n",
        "\n",
        "//Wait for thread to finish.\n",
        "void end_thread( CUTThread thread );\n",
        "\n",
        "//Destroy thread.\n",
        "void destroy_thread( CUTThread thread );\n",
        "\n",
        "//Wait for multiple threads.\n",
        "void wait_for_threads( const CUTThread *threads, int num );\n",
        "\n",
        "#if _WIN32\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void *data){\n",
        "        return CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)func, data, 0, NULL);\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        WaitForSingleObject(thread, INFINITE);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        TerminateThread(thread, 0);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        WaitForMultipleObjects(num, threads, true, INFINITE);\n",
        "\n",
        "        for(int i = 0; i < num; i++)\n",
        "            CloseHandle(threads[i]);\n",
        "    }\n",
        "\n",
        "#else\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void * data){\n",
        "        pthread_t thread;\n",
        "        pthread_create(&thread, NULL, func, data);\n",
        "        return thread;\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        pthread_join(thread, NULL);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        pthread_cancel(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        for(int i = 0; i < num; i++)\n",
        "            end_thread( threads[i] );\n",
        "    }\n",
        "\n",
        "#endif\n",
        "\n",
        "#endif  // __UTILS_H__"
      ],
      "metadata": {
        "id": "o8DiZxqTVzyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Reduction via produit scalaire\n",
        "\n",
        "### Implémentez le kernel : \n",
        "\n",
        "#### 1.1 Creez le vecteur **cache** de type float et de taille **threadsPerBlock**;\n",
        "#### 1.2 Trouver l'index global des threads\n",
        "#### 1.3 Comme pour l'addition vectoriel, multipliez les éléments d'index tid des vecteurs a et b entre eux. Puis stockez le résultat dans le cache.\n",
        "#### 1.4 implémentez la reduction comme énoncé dans github.\n",
        "\n",
        "#### 1.5 Completez le main afin de pouvoir exécuter le programme\n",
        "- Allocation mémoire\n",
        "- Copie mémoire H2D\n",
        "- Lancement du kernel\n",
        "- Copie mémoire D2H\n",
        "- Liberation de la mémoire"
      ],
      "metadata": {
        "id": "uB1BFcg5Qxb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile program.cu\n",
        "#include \"utils.h\"\n",
        "\n",
        "\n",
        "const int N = 33792;\n",
        "const int threadsPerBlock = 256;\n",
        "const int blocksPerGrid = (N+threadsPerBlock-1) / threadsPerBlock;\n",
        "\n",
        "\n",
        "__global__ void produit_scalaire( float *a, float *b, float *c ) {\n",
        "    // 1.1 Creation du vecteur cache dans la mémoire partagée.\n",
        "\n",
        "\n",
        "    // 1.2 Trouver l'index global de chaque thread (on est en 1D) et l'index local cacheIndex dans la mémoire partagée.\n",
        "    int tid = \n",
        "    int cacheIndex = \n",
        "\n",
        "    // 1.3 Comme pour l'addition vectoriel, multipliez les éléments d'index tid des vecteurs a et b entre eux. Puis stockez le résultat dans le cache.\n",
        "    float temp =\n",
        "    while (tid < N) {\n",
        "        temp += \n",
        "        // Si vous n'avez pas assez de thread pour faire le calcul. Chaque thread va tenter de modifier son id avec un offset égale au nombre total de threads.\n",
        "        tid += \n",
        "    }\n",
        "\n",
        "    //1.4 implémentez la reduction comme énoncé dans github.\n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "int main( void ) {\n",
        "    float   *a, *b, c, *partial_c;\n",
        "    float   *dev_a, *dev_b, *dev_partial_c;\n",
        "\n",
        "    \n",
        "    \n",
        "    a = (float*)malloc( N*sizeof(float) );\n",
        "    b = (float*)malloc( N*sizeof(float) );\n",
        "    partial_c = (float*)malloc( blocksPerGrid*sizeof(float) );\n",
        "\n",
        "    for (int i=0; i<N; i++) {\n",
        "        a[i] = i;\n",
        "        b[i] = i*2;\n",
        "    }\n",
        "\n",
        "    // 1.5 Completez le code.\n",
        "    \n",
        "\n",
        "    // On somme les éléments de partial_c pour terminer la reduction.\n",
        "    c = 0;\n",
        "    for (int i=0; i<blocksPerGrid; i++) {\n",
        "        c += partial_c[i];\n",
        "    }\n",
        "\n",
        "    #define sum_squares(x)  (x*(x+1)*(2*x+1)/6)\n",
        "    printf( \"Does GPU value %.6g = %.6g?\\n\", c,\n",
        "             2 * sum_squares( (float)(N - 1) ) );\n",
        "\n",
        "    // free memory on the cpu side\n",
        "    free( a );\n",
        "    free( b );\n",
        "    free( partial_c );\n",
        "}"
      ],
      "metadata": {
        "id": "Rm-7gDO8BGH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "PfakPQ1CHLUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./program"
      ],
      "metadata": {
        "id": "F4BRhsCtHLo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Multiplication matricielle 3D\n",
        "\n",
        "### Version 1 : Mémoire globale\n",
        "\n",
        "Completez le kernel matrixMul3D \n",
        "\n",
        "#### 2.1 Trouver le bon index des threads pour les colonnes (col) les lignes (row) et la profondeur (depth).\n",
        "\n",
        "#### 2.2 Implémentez le produit scalaire\n",
        "Rappel : Chaque thread effectue le produit scalaire entre une ligne de **a** et une colonne de **b**\n",
        "\n",
        "Chaque thread itere donc sur les éléments d'une ligne de a (qui est de même taille qu'une colonne de b), le multiplie avec l'élément correspondant de la colonne de b, puis ajoute le resultat dans un registe **sum**.\n",
        "\n",
        "A la fin de la boucle, sum contient le resultat du produit scalaire que l'on vient mettre dans **c**.\n",
        "\n",
        "#### 2.3 Complétez la fonction main afin de pouvoir lancer le programme avec le kernel MatrixMul3D.\n",
        "- Allocation mémoire\n",
        "- Copie mémoire H2D\n",
        "- Lancement du kernel\n",
        "- Copie mémoire D2H\n",
        "- Liberation de la mémoire\n",
        "\n",
        "### Version 2 : Mémoire partagée.\n",
        "\n",
        "#### 2.4 Creez les matrices 3D shared_a et shared_b dans la mémoire partagée, de type int et de taille BLOCK_SIZExBLOCK_SIZExBLOCK_SIZE.\n",
        "\n",
        "#### 2.5 Trouver le bon index des threads pour les colonnes (col) les lignes (row) et la profondeur (depth).\n",
        "\n",
        "#### 2.6 Implémentez le produit matriciel dans la mémoire partagée.\n",
        "Cette fois ci, on ne calcule pas le produit matriciel au niveau du thread mais au niveau d'un bloc de threads.\n",
        "\n",
        "Dans cet exercice, un bloc est de taille 2x2x2. Il y aura donc, pour un bloc, 8 threads qui vont calculer le produit matriciel entre une ligne de shared_a et une colonne de shared_b.\n",
        "\n",
        "Cependant, shared_a et shared_b sont de taille 2x2x2 et non pas de taille nxnxn. Il faut donc pour chaque thread iterer le nombre de blocs en x d'une grille (gridDim.x), décaler shared_a vers la droite (de façon horizontal) en utilisant un offset (**h_stride**), et décaler shared_b vers le bas (de façon vertical en utilisant un offset (**v_stride**). Voir Figure sur github.\n",
        "\n",
        "Pensez a synchroniser les threads lorsque vous modifiez/récupérez des valeurs dans la mémoire partagée.\n",
        "\n",
        "\n",
        "#### 2.7 Executez le code en remplaçant matrixMul3D par shared_matrixMul3D\n",
        "Vous devez obtenir le même resultat pour les dexu versions."
      ],
      "metadata": {
        "id": "hrMijrhjbjJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile program.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "#define BLOCK_SIZE 2\n",
        "__global__ void matrixMul3D(int *a, int *b, int *c, int n)\n",
        "{\n",
        "    \n",
        "    // 2.1 Indexation des threads\n",
        "    int col = \n",
        "    int row = \n",
        "    int depth = \n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // 2.2 Produit scalaire\n",
        "    if (depth < n && row < n && col < n) {\n",
        "        \n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void shared_matrixMul3D(int *a, int *b, int *c, int n)\n",
        "{\n",
        "    \n",
        "    // 2.4 Creez les matrices 3D shared_a et shared_b dans la mémoire partagée, de type int et de taille BLOCK_SIZE*BLOCK_SIZE*BLOCK_SIZE.\n",
        "\n",
        "\n",
        "    // 2.5 Trouver le bon index des threads pour les colonnes (col) les lignes (row) et la profondeur (depth).\n",
        "    int col = \n",
        "    int row = \n",
        "    int depth = \n",
        "\n",
        "    int sum = 0;\n",
        "    // 2.6 Implémentez le produit matriciel dans la mémoire partagée.\n",
        "    for(int m = 0; m < gridDim.x; m++){\n",
        "\n",
        "      int h_stride = \n",
        "      int v_stride = \n",
        "      shared_a[threadIdx.z][threadIdx.y][threadIdx.x] = \n",
        "      shared_b[threadIdx.z][threadIdx.y][threadIdx.x] = \n",
        "\n",
        "      // A completer\n",
        "    }\n",
        "    \n",
        "    c[A completez] = sum;\n",
        "}\n",
        "\n",
        "void print_matrix(int*a, int n){\n",
        "  for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            for (int k = 0; k < n; k++) {\n",
        "                printf(\"%d\\t\", a[i*n*n + j * n + k]);\n",
        "            }\n",
        "        printf(\"\\n\");\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int n = 4;\n",
        "    int size = n * n * n * sizeof(float);\n",
        "    int *h_a = (int*)malloc(size);\n",
        "    int *h_b = (int*)malloc(size);\n",
        "    int *h_c = (int*)malloc(size);\n",
        "    for (int i = 0; i < n * n * n; ++i) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i*2;\n",
        "    }\n",
        "    printf(\"Matrix a :\\n\");\n",
        "    print_matrix(h_a, n);\n",
        "    printf(\"Matrix b :\\n\");\n",
        "    print_matrix(h_b, n);\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    // 2.3 Completez la fonction main.\n",
        "    \n",
        "    printf(\"Matrix c :\\n\");\n",
        "    print_matrix(h_c, n);\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "QKhzrIKZiMcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825abb02-58bc-40f2-e921-97a19ae9712f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting program.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "fZNKLH3Cz-Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./program"
      ],
      "metadata": {
        "id": "Zn-q9uA1n7o6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}