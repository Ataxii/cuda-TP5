{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration de Cuda dans Google Colab"
      ],
      "metadata": {
        "id": "qE-HbkLWqjJK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OJjU5zI_-tjl",
        "outputId": "a108f78a-4e5a-4c1f-9a54-ecdfde9a405d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc -V  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "HBZjh4P4-1HE",
        "outputId": "a95b28aa-ad75-4022-bdb3-f1543f25c538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-wr0izjtj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-wr0izjtj\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=33d07f74a3959244d9ecf6ecfb400f6b3112d6d4fdbbb6702718cb9b9ac9a247\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f36ihvnr/wheels/db/c1/1f/a2bb07bbb4a1ce3c43921252aeafaa6205f08637e292496f04\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On vérifie que l'on est bien connecté au GPU"
      ],
      "metadata": {
        "id": "YJw3IWdqtpfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "9gl_4Pn7_JR2",
        "outputId": "17155109-3fd7-488e-d02c-0f394a16812b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 31 12:40:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chargement du plugin nvcc permettant de compiler/executer les programmes Cuda"
      ],
      "metadata": {
        "id": "NlBBvVVOt4Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "6YGSePh_Q_DP",
        "outputId": "20408a0d-10ad-461e-9af5-11563742f6b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Un makefile est déjà à votre disposition pour compiler les programme du TP\n"
      ],
      "metadata": {
        "id": "0zrHyBuVuQpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Executez la cellule du Makefile\n",
        "\n",
        "Le makefile a été modifié pour les programmes puisse s'exécuter avec la GPU premium.\n",
        "\n"
      ],
      "metadata": {
        "id": "AWS3uSGwu2o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Makefile\n",
        "# Change the example variable to build a different source module (e.g. EXAMPLE=exercice01)\n",
        "EXAMPLE=program\n",
        "\n",
        "# Makefile variables \n",
        "# Add extra targets to OBJ with space separator e.g. If there is as source file random.c then add random.o to OBJ)\n",
        "# Add any additional dependancies (header files) to DEPS. e.g. if there is aheader file random.h required by your source modules then add this to DEPS.\n",
        "CC=gcc\n",
        "CFLAGS= -O3 -Wextra -fopenmp\n",
        "NVCC=nvcc\n",
        "NVCC_FLAGS= -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87\n",
        "OBJ=$(EXAMPLE).o\n",
        "DEPS=\n",
        "\n",
        "# Build rule for object files ($@ is left hand side of rule, $< is first item from the right hand side of rule)\n",
        "%.o : %.cu $(DEPS)\n",
        "\t$(NVCC) -c -o $@ $< $(NVCC_FLAGS) $(addprefix -Xcompiler ,$(CCFLAGS))\n",
        "\n",
        "# Make example ($^ is all items from right hand side of the rule)\n",
        "$(EXAMPLE) : $(OBJ)\n",
        "\t$(NVCC) -o $@ $^ $(NVCC_FLAGS) $(addprefix -Xcompiler ,$(CCFLAGS))\n",
        "\n",
        "# PHONY prevents make from doing something with a filename called clean\n",
        ".PHONY : clean\n",
        "clean:\n",
        "\trm -rf $(EXAMPLE) $(OBJ)"
      ],
      "metadata": {
        "id": "2VMs5wjdRU0g",
        "outputId": "4087a709-ec1c-4b75-9f84-2b7b2a0d3f7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Makefile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP5\n",
        "\n"
      ],
      "metadata": {
        "id": "ri3OU-i0vt2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.h\n",
        "#ifndef __UTILS_H__\n",
        "#define __UTILS_H__\n",
        "#include <stdio.h>\n",
        "\n",
        "static void HandleError( cudaError_t err,\n",
        "                         const char *file,\n",
        "                         int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))\n",
        "\n",
        "\n",
        "#define HANDLE_NULL( a ) {if (a == NULL) { \\\n",
        "                            printf( \"Host memory failed in %s at line %d\\n\", \\\n",
        "                                    __FILE__, __LINE__ ); \\\n",
        "                            exit( EXIT_FAILURE );}}\n",
        "\n",
        "template< typename T >\n",
        "void swap( T& a, T& b ) {\n",
        "    T t = a;\n",
        "    a = b;\n",
        "    b = t;\n",
        "}\n",
        "\n",
        "\n",
        "void* big_random_block( int size ) {\n",
        "    unsigned char *data = (unsigned char*)malloc( size );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "int* big_random_block_int( int size ) {\n",
        "    int *data = (int*)malloc( size * sizeof(int) );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "\n",
        "// a place for common kernels - starts here\n",
        "\n",
        "__device__ unsigned char value( float n1, float n2, int hue ) {\n",
        "    if (hue > 360)      hue -= 360;\n",
        "    else if (hue < 0)   hue += 360;\n",
        "\n",
        "    if (hue < 60)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*hue/60));\n",
        "    if (hue < 180)\n",
        "        return (unsigned char)(255 * n2);\n",
        "    if (hue < 240)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*(240-hue)/60));\n",
        "    return (unsigned char)(255 * n1);\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( unsigned char *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset*4 + 0] = value( m1, m2, h+120 );\n",
        "    optr[offset*4 + 1] = value( m1, m2, h );\n",
        "    optr[offset*4 + 2] = value( m1, m2, h -120 );\n",
        "    optr[offset*4 + 3] = 255;\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( uchar4 *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset].x = value( m1, m2, h+120 );\n",
        "    optr[offset].y = value( m1, m2, h );\n",
        "    optr[offset].z = value( m1, m2, h -120 );\n",
        "    optr[offset].w = 255;\n",
        "}\n",
        "\n",
        "\n",
        "#if _WIN32\n",
        "    //Windows threads.\n",
        "    #include <windows.h>\n",
        "\n",
        "    typedef HANDLE CUTThread;\n",
        "    typedef unsigned (WINAPI *CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC unsigned WINAPI\n",
        "    #define  CUT_THREADEND return 0\n",
        "\n",
        "#else\n",
        "    //POSIX threads.\n",
        "    #include <pthread.h>\n",
        "\n",
        "    typedef pthread_t CUTThread;\n",
        "    typedef void *(*CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC void\n",
        "    #define  CUT_THREADEND\n",
        "#endif\n",
        "\n",
        "//Create thread.\n",
        "CUTThread start_thread( CUT_THREADROUTINE, void *data );\n",
        "\n",
        "//Wait for thread to finish.\n",
        "void end_thread( CUTThread thread );\n",
        "\n",
        "//Destroy thread.\n",
        "void destroy_thread( CUTThread thread );\n",
        "\n",
        "//Wait for multiple threads.\n",
        "void wait_for_threads( const CUTThread *threads, int num );\n",
        "\n",
        "#if _WIN32\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void *data){\n",
        "        return CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)func, data, 0, NULL);\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        WaitForSingleObject(thread, INFINITE);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        TerminateThread(thread, 0);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        WaitForMultipleObjects(num, threads, true, INFINITE);\n",
        "\n",
        "        for(int i = 0; i < num; i++)\n",
        "            CloseHandle(threads[i]);\n",
        "    }\n",
        "\n",
        "#else\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void * data){\n",
        "        pthread_t thread;\n",
        "        pthread_create(&thread, NULL, func, data);\n",
        "        return thread;\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        pthread_join(thread, NULL);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        pthread_cancel(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        for(int i = 0; i < num; i++)\n",
        "            end_thread( threads[i] );\n",
        "    }\n",
        "\n",
        "#endif\n",
        "\n",
        "#endif  // __UTILS_H__"
      ],
      "metadata": {
        "id": "o8DiZxqTVzyD",
        "outputId": "af963d47-f25e-4665-ff29-82a8a0dabe85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Reduction via produit scalaire\n",
        "\n",
        "### Implémentez le kernel : \n",
        "\n",
        "#### 1.1 Creez le vecteur **cache** de type float et de taille **threadsPerBlock**;\n",
        "#### 1.2 Trouver l'index global des threads\n",
        "#### 1.3 Comme pour l'addition vectoriel, multipliez les éléments d'index tid des vecteurs a et b entre eux. Puis stockez le résultat dans le cache.\n",
        "#### 1.4 implémentez la reduction comme énoncé dans github.\n",
        "\n",
        "#### 1.5 Completez le main afin de pouvoir exécuter le programme\n",
        "- Allocation mémoire\n",
        "- Copie mémoire H2D\n",
        "- Lancement du kernel\n",
        "- Copie mémoire D2H\n",
        "- Liberation de la mémoire"
      ],
      "metadata": {
        "id": "uB1BFcg5Qxb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile program.cu\n",
        "#include \"utils.h\"\n",
        "\n",
        "\n",
        "const int N = 33792;\n",
        "const int threadsPerBlock = 256;\n",
        "const int blocksPerGrid = (N+threadsPerBlock-1) / threadsPerBlock;\n",
        "\n",
        "\n",
        "__global__ void produit_scalaire( float *a, float *b, float *c ) {\n",
        "    // 1.1 Creation du vecteur cache dans la mémoire partagée.\n",
        "    __shared__ float cache[threadsPerBlock];\n",
        "\n",
        "    // 1.2 Trouver l'index global de chaque thread (on est en 1D) et l'index local cacheIndex dans la mémoire partagée.\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int cacheIndex = threadIdx.x;\n",
        "\n",
        "    // 1.3 Comme pour l'addition vectoriel, multipliez les éléments d'index tid des vecteurs a et b entre eux. Puis stockez le résultat dans le cache.\n",
        "    float temp = 0;\n",
        "    while (tid < N) {\n",
        "        temp += a[tid] * b[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "    cache[cacheIndex] = temp;\n",
        "\n",
        "    //1.4 implémentez la reduction comme énoncé dans github.\n",
        "    __syncthreads();\n",
        "\n",
        "    int i = blockDim.x/2;\n",
        "    while (i != 0) {\n",
        "        if (cacheIndex < i) {\n",
        "            cache[cacheIndex] += cache[cacheIndex + i];\n",
        "        }\n",
        "        __syncthreads();\n",
        "        i /= 2;\n",
        "    }\n",
        "\n",
        "    if (cacheIndex == 0) {\n",
        "        c[blockIdx.x] = cache[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main( void ) {\n",
        "    float   *a, *b, c, *partial_c;\n",
        "    float   *dev_a, *dev_b, *dev_partial_c;\n",
        "\n",
        "    a = (float*)malloc( N*sizeof(float) );\n",
        "    b = (float*)malloc( N*sizeof(float) );\n",
        "    partial_c = (float*)malloc( blocksPerGrid*sizeof(float) );\n",
        "\n",
        "    for (int i=0; i<N; i++) {\n",
        "      a[i] = i;\n",
        "      b[i] = i*2;\n",
        "    }\n",
        "\n",
        "    // Allocation memoire sur le GPU\n",
        "    cudaMalloc(&dev_a, N * sizeof(float));\n",
        "    cudaMalloc(&dev_b, N * sizeof(float));\n",
        "    cudaMalloc(&dev_partial_c, blocksPerGrid * sizeof(float));\n",
        "\n",
        "    // Copie des donnees de l'hote vers le GPU\n",
        "    cudaMemcpy(dev_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lancement du kernel avec blocksPerGrid blocs et threadsPerBlock threads par bloc\n",
        "    produit_scalaire<<<blocksPerGrid, threadsPerBlock>>>(dev_a, dev_b, dev_partial_c);\n",
        "\n",
        "    // Copie du résultat partiel du GPU vers l'hote\n",
        "    cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Reduction des résultats partiels sur le CPU\n",
        "    c = 0;\n",
        "    for (int i=0; i<blocksPerGrid; i++) {\n",
        "      c += partial_c[i];\n",
        "    }\n",
        "\n",
        "    #define sum_squares(x)  (x*(x+1)*(2*x+1)/6)\n",
        "    printf( \"Does GPU value %.6g = %.6g?\\n\", c,\n",
        "         2 * sum_squares( (float)(N - 1) ) );\n",
        "\n",
        "    // Liberation de la memoire sur le CPU et le GPU\n",
        "    free( a );\n",
        "    free( b );\n",
        "    free( partial_c );\n",
        "\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_partial_c);\n",
        "}"
      ],
      "metadata": {
        "id": "Rm-7gDO8BGH_",
        "outputId": "a73e1aa0-7148-4922-e1df-d5f13ebb9322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing program.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "PfakPQ1CHLUp",
        "outputId": "afcade90-bab1-48c0-c349-ef2ce4ca8b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -c -o program.o program.cu -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 \n",
            "nvcc -o program program.o -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./program"
      ],
      "metadata": {
        "id": "F4BRhsCtHLo6",
        "outputId": "cc1730c7-cadc-486c-ffe4-d08e3fbfeca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does GPU value 2.57236e+13 = 2.57236e+13?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Multiplication matricielle 3D\n",
        "\n",
        "### Version 1 : Mémoire globale\n",
        "\n",
        "Completez le kernel matrixMul3D \n",
        "\n",
        "#### 2.1 Trouver le bon index des threads pour les colonnes (col) les lignes (row) et la profondeur (depth).\n",
        "\n",
        "#### 2.2 Implémentez le produit scalaire\n",
        "Rappel : Chaque thread effectue le produit scalaire entre une ligne de **a** et une colonne de **b**\n",
        "\n",
        "Chaque thread itere donc sur les éléments d'une ligne de a (qui est de même taille qu'une colonne de b), le multiplie avec l'élément correspondant de la colonne de b, puis ajoute le resultat dans un registe **sum**.\n",
        "\n",
        "A la fin de la boucle, sum contient le resultat du produit scalaire que l'on vient mettre dans **c**.\n",
        "\n",
        "#### 2.3 Complétez la fonction main afin de pouvoir lancer le programme avec le kernel MatrixMul3D.\n",
        "- Allocation mémoire\n",
        "- Copie mémoire H2D\n",
        "- Lancement du kernel\n",
        "- Copie mémoire D2H\n",
        "- Liberation de la mémoire\n",
        "\n",
        "### Version 2 : Mémoire partagée.\n",
        "\n",
        "#### 2.4 Creez les matrices 3D shared_a et shared_b dans la mémoire partagée, de type int et de taille BLOCK_SIZExBLOCK_SIZExBLOCK_SIZE.\n",
        "\n",
        "#### 2.5 Trouver le bon index des threads pour les colonnes (col) les lignes (row) et la profondeur (depth).\n",
        "\n",
        "#### 2.6 Implémentez le produit matriciel dans la mémoire partagée.\n",
        "Cette fois ci, on ne calcule pas le produit matriciel au niveau du thread mais au niveau d'un bloc de threads.\n",
        "\n",
        "Dans cet exercice, un bloc est de taille 2x2x2. Il y aura donc, pour un bloc, 8 threads qui vont calculer le produit matriciel entre une ligne de shared_a et une colonne de shared_b.\n",
        "\n",
        "Cependant, shared_a et shared_b sont de taille 2x2x2 et non pas de taille nxnxn. Il faut donc pour chaque thread iterer le nombre de blocs en x d'une grille (gridDim.x), décaler shared_a vers la droite (de façon horizontal) en utilisant un offset (**h_stride**), et décaler shared_b vers le bas (de façon vertical en utilisant un offset (**v_stride**). Voir Figure sur github.\n",
        "\n",
        "Pensez a synchroniser les threads lorsque vous modifiez/récupérez des valeurs dans la mémoire partagée.\n",
        "\n",
        "\n",
        "#### 2.7 Executez le code en remplaçant matrixMul3D par shared_matrixMul3D\n",
        "Vous devez obtenir le même resultat pour les dexu versions."
      ],
      "metadata": {
        "id": "hrMijrhjbjJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile program.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "#define BLOCK_SIZE 2\n",
        "__global__ void matrixMul3D(int *a, int *b, int *c, int n)\n",
        "{\n",
        "    \n",
        "    // 2.1 Indexation des threads\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int depth = threadIdx.z;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // 2.2 Produit scalaire\n",
        "    if (depth < n && row < n && col < n) {\n",
        "\n",
        "        for (int k = 0; k < n; k++) {\n",
        "            //sum += a[depth * n * n + row * n + k] * b[k * n * n + col * n + depth];\n",
        "            sum += a[depth * n * n + row * n + k] * b[k * n + col];        }\n",
        "        c[depth * n * n + row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void shared_matrixMul3D(int *a, int *b, int *c, int n)\n",
        "{\n",
        "    // 2.4 Creez les matrices 3D shared_a et shared_b dans la mémoire partagée, de type int et de taille BLOCK_SIZE*BLOCK_SIZE*BLOCK_SIZE.\n",
        "    __shared__ int shared_a[BLOCK_SIZE][BLOCK_SIZE][BLOCK_SIZE];\n",
        "    __shared__ int shared_b[BLOCK_SIZE][BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "    // 2.5 Trouver le bon index des threads pour les colonnes (col) les lignes (row) et la profondeur (depth).\n",
        "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int depth = threadIdx.z + blockIdx.z * blockDim.z;\n",
        "\n",
        "    int sum = 0;\n",
        "    // 2.6 Implémentez le produit matriciel dans la mémoire partagée.\n",
        "    for (int m = 0; m < gridDim.x; m++) {\n",
        "\n",
        "        int h_stride = m * BLOCK_SIZE;\n",
        "        int v_stride = m * BLOCK_SIZE  ;\n",
        "        shared_a[threadIdx.z][threadIdx.y][threadIdx.x] = a[depth * n * n + row * n + h_stride + threadIdx.x];\n",
        "        shared_b[threadIdx.z][threadIdx.y][threadIdx.x] = b[(v_stride + threadIdx.y) * n + col + threadIdx.x];\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int i = 0; i < BLOCK_SIZE; i++) {\n",
        "          if((depth * n * n + row * n + col) == 5){\n",
        "                printf(\"valeur de x : %i , valeur de y : %i \\n\", shared_a[threadIdx.z][threadIdx.y][i], shared_b[threadIdx.z][i][threadIdx.x]);\n",
        "          }\n",
        "            sum += shared_a[threadIdx.z][threadIdx.y][i] * shared_b[threadIdx.z][i][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "\n",
        "    c[depth * n * n + row * n + col] = sum;\n",
        "}\n",
        "\n",
        "void print_matrix(int*a, int n){\n",
        "  for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            for (int k = 0; k < n; k++) {\n",
        "                printf(\"%d\\t\", a[i*n*n + j * n + k]);\n",
        "            }\n",
        "        printf(\"\\n\");\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int n = 4;\n",
        "    int size = n * n * n * sizeof(int);\n",
        "    int *h_a = (int*)malloc(size);\n",
        "    int *h_b = (int*)malloc(size);\n",
        "    int *h_c = (int*)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < n * n * n; ++i) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i*2;\n",
        "    }\n",
        "    printf(\"Matrix a :\\n\");\n",
        "    print_matrix(h_a, n);\n",
        "    printf(\"Matrix b :\\n\");\n",
        "    print_matrix(h_b, n);\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    // 2.3 Completez la fonction main.\n",
        "\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    ////// SHARED VERSION ///////\n",
        "\n",
        "    dim3 threadsPerBlock(BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 blocksPerGrid((n + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                       (n + threadsPerBlock.y - 1) / threadsPerBlock.y,\n",
        "                       (n + threadsPerBlock.z - 1) / threadsPerBlock.z);\n",
        "\n",
        "    shared_matrixMul3D<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost); \n",
        "\n",
        "    printf(\"Matrix c :\\n\");\n",
        "    print_matrix(h_c, n);\n",
        "\n",
        "    ////// NORMAL VERSION ///////\n",
        "\n",
        "    dim3 threadsPerBlock2(BLOCK_SIZE * 2, BLOCK_SIZE * 2, BLOCK_SIZE * 2);\n",
        "    dim3 blocksPerGrid2(BLOCK_SIZE, BLOCK_SIZE,  BLOCK_SIZE);\n",
        "\n",
        "    matrixMul3D<<<blocksPerGrid2, threadsPerBlock2>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost); \n",
        "\n",
        "    printf(\"Matrix c :\\n\");\n",
        "    print_matrix(h_c, n);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "QKhzrIKZiMcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bafc52-6824-465e-acc4-6fb31f46db7a"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting program.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "fZNKLH3Cz-Ly",
        "outputId": "2191d546-0823-407c-8a73-5094a9401a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -c -o program.o program.cu -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 \n",
            "nvcc -o program program.o -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./program"
      ],
      "metadata": {
        "id": "Zn-q9uA1n7o6",
        "outputId": "7cecc161-5d32-48a4-aab5-f489e785d65a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix a :\n",
            "0\t1\t2\t3\t\n",
            "4\t5\t6\t7\t\n",
            "8\t9\t10\t11\t\n",
            "12\t13\t14\t15\t\n",
            "\n",
            "16\t17\t18\t19\t\n",
            "20\t21\t22\t23\t\n",
            "24\t25\t26\t27\t\n",
            "28\t29\t30\t31\t\n",
            "\n",
            "32\t33\t34\t35\t\n",
            "36\t37\t38\t39\t\n",
            "40\t41\t42\t43\t\n",
            "44\t45\t46\t47\t\n",
            "\n",
            "48\t49\t50\t51\t\n",
            "52\t53\t54\t55\t\n",
            "56\t57\t58\t59\t\n",
            "60\t61\t62\t63\t\n",
            "\n",
            "Matrix b :\n",
            "0\t2\t4\t6\t\n",
            "8\t10\t12\t14\t\n",
            "16\t18\t20\t22\t\n",
            "24\t26\t28\t30\t\n",
            "\n",
            "32\t34\t36\t38\t\n",
            "40\t42\t44\t46\t\n",
            "48\t50\t52\t54\t\n",
            "56\t58\t60\t62\t\n",
            "\n",
            "64\t66\t68\t70\t\n",
            "72\t74\t76\t78\t\n",
            "80\t82\t84\t86\t\n",
            "88\t90\t92\t94\t\n",
            "\n",
            "96\t98\t100\t102\t\n",
            "104\t106\t108\t110\t\n",
            "112\t114\t116\t118\t\n",
            "120\t122\t124\t126\t\n",
            "\n",
            "valeur de x : 4 , valeur de y : 4 \n",
            "valeur de x : 5 , valeur de y : 12 \n",
            "valeur de x : 6 , valeur de y : 20 \n",
            "valeur de x : 7 , valeur de y : 28 \n",
            "Matrix c :\n",
            "112\t136\t136\t160\t\n",
            "304\t392\t392\t480\t\n",
            "496\t648\t648\t800\t\n",
            "688\t904\t904\t1120\t\n",
            "\n",
            "880\t1160\t1160\t1440\t\n",
            "1072\t1416\t1416\t1760\t\n",
            "1264\t1672\t1672\t2080\t\n",
            "1456\t1928\t1928\t2400\t\n",
            "\n",
            "1648\t2184\t2184\t2720\t\n",
            "1840\t2440\t2440\t3040\t\n",
            "2032\t2696\t2696\t3360\t\n",
            "2224\t2952\t2952\t3680\t\n",
            "\n",
            "2416\t3208\t3208\t4000\t\n",
            "2608\t3464\t3464\t4320\t\n",
            "2800\t3720\t3720\t4640\t\n",
            "2992\t3976\t3976\t4960\t\n",
            "\n",
            "Matrix c :\n",
            "112\t124\t136\t148\t\n",
            "304\t348\t392\t436\t\n",
            "496\t572\t648\t724\t\n",
            "688\t796\t904\t1012\t\n",
            "\n",
            "880\t1020\t1160\t1300\t\n",
            "1072\t1244\t1416\t1588\t\n",
            "1264\t1468\t1672\t1876\t\n",
            "1456\t1692\t1928\t2164\t\n",
            "\n",
            "1648\t1916\t2184\t2452\t\n",
            "1840\t2140\t2440\t2740\t\n",
            "2032\t2364\t2696\t3028\t\n",
            "2224\t2588\t2952\t3316\t\n",
            "\n",
            "2416\t2812\t3208\t3604\t\n",
            "2608\t3036\t3464\t3892\t\n",
            "2800\t3260\t3720\t4180\t\n",
            "2992\t3484\t3976\t4468\t\n",
            "\n"
          ]
        }
      ]
    }
  ]
}